{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1899f903",
   "metadata": {},
   "source": [
    "# Poultry Disease Classification from Fecal Images\n",
    "\n",
    "This notebook classifies poultry diseases based on fecal images into four classes:\n",
    "\n",
    "- **Healthy**\n",
    "- **Coccidiosis (cocci)**\n",
    "- **Salmonella (salmo)**\n",
    "- **Newcastle Disease (ncd)**\n",
    "\n",
    "> ‚öôÔ∏è *The model is optimized for Mac M1 with 8GB RAM.* (Farhan Mashrur)\n",
    "- Model initially developed with Ahmed Abdulla (Teammate) for Mac M2 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27fc4e4",
   "metadata": {},
   "source": [
    "### GPU availability Testing :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f1f19079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.16.2\n",
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Num GPUs Available: 1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPUs:\", tf.config.list_physical_devices('GPU'))\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe6b22a",
   "metadata": {},
   "source": [
    " ## 1. Importing Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d3bde5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam, Adamax\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# Enable mixed precision for Apple Silicon (M1/M2)\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print('Modules loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811654e8",
   "metadata": {},
   "source": [
    "## 2. Enable GPU Acceleration (for Mac M1)\n",
    "#### For Mac M1, we are using TensorFlow-MacOS and Metal plugin are installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a490c415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU acceleration enabled on M1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    if len(physical_devices) > 0:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "        print(\"GPU acceleration enabled on M1\")\n",
    "    else:\n",
    "        print(\"No GPU found\")\n",
    "except Exception as e:\n",
    "    print(\"GPU acceleration not available:\", e)\n",
    "\n",
    "\n",
    "# 3. Image Settings for Mac M1 (8GB RAM)\n",
    "IMG_SIZE = (160, 160)  # Reduced for efficiency\n",
    "CHANNELS = 3\n",
    "BATCH_SIZE = 32        # Lower to 16 if memory issues occur\n",
    "IMG_SHAPE = (IMG_SIZE[0], IMG_SIZE[1], CHANNELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b559392",
   "metadata": {},
   "source": [
    "## 3) Custom Callback for training and Monitoring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f6d2d274",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "class MyCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, model, patience=1, stop_patience=3, threshold=0.9, factor=0.5, batches=None, epochs=None):\n",
    "        super(MyCallback, self).__init__()\n",
    "        self._model = model\n",
    "        self.patience = patience \n",
    "        self.stop_patience = stop_patience\n",
    "        self.threshold = threshold\n",
    "        self.factor = factor\n",
    "        self.batches = batches\n",
    "        self.epochs = epochs\n",
    "        \n",
    "        self.count = 0\n",
    "        self.stop_count = 0\n",
    "        self.best_epoch = 1\n",
    "        \n",
    "        try:\n",
    "            self.current_lr = 0.001\n",
    "            if hasattr(model.optimizer, 'learning_rate'):\n",
    "                lr = model.optimizer.learning_rate\n",
    "                if hasattr(lr, 'numpy'):\n",
    "                    self.current_lr = float(lr.numpy())\n",
    "            elif hasattr(model.optimizer, 'lr'):\n",
    "                lr = model.optimizer.lr\n",
    "                if hasattr(lr, 'numpy'):\n",
    "                    self.current_lr = float(lr.numpy())\n",
    "        except:\n",
    "            self.current_lr = 0.001\n",
    "            \n",
    "        self.initial_lr = self.current_lr\n",
    "        self.highest_tracc = 0.0\n",
    "        self.lowest_vloss = np.inf\n",
    "        self.best_weights = self._model.get_weights()\n",
    "        self.initial_weights = self._model.get_weights()\n",
    "\n",
    "        print(\"‚úÖ Callback initialization complete.\")\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        msg = '{0:^8s}{1:^10s}{2:^9s}{3:^9s}{4:^9s}{5:^9s}{6:^9s}{7:^10s}{8:10s}{9:^8s}'.format(\n",
    "            'Epoch', 'Loss', 'Accuracy', 'V_loss', 'V_acc', 'LR', 'Next LR', 'Monitor','% Improv', 'Duration')\n",
    "        print(msg)\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        stop_time = time.time()\n",
    "        tr_duration = stop_time - self.start_time\n",
    "        hours = tr_duration // 3600\n",
    "        minutes = (tr_duration - (hours * 3600)) // 60\n",
    "        seconds = tr_duration - ((hours * 3600) + (minutes * 60))\n",
    "        msg = f'\\nTraining time: {int(hours)}h {int(minutes)}m {seconds:.2f}s'\n",
    "        print(msg)\n",
    "        self._model.set_weights(self.best_weights)\n",
    "        print(\"‚úÖ Best weights restored.\")\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        acc = logs.get('accuracy') * 100\n",
    "        loss = logs.get('loss')\n",
    "        msg = f'processing batch {batch + 1} of {self.batches} - accuracy: {acc:.2f}% - loss: {loss:.5f}'\n",
    "        print(msg, '\\r', end='')\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.ep_start = time.time()\n",
    "        print(f\"\\nüîÅ Starting epoch {epoch + 1}\")\n",
    "\n",
    "    def _update_lr(self, new_lr):\n",
    "        try:\n",
    "            if hasattr(self._model.optimizer, 'learning_rate'):\n",
    "                tf.keras.backend.set_value(self._model.optimizer.learning_rate, new_lr)\n",
    "            elif hasattr(self._model.optimizer, 'lr'):\n",
    "                tf.keras.backend.set_value(self._model.optimizer.lr, new_lr)\n",
    "            self.current_lr = new_lr\n",
    "            print(f\"üìâ Learning rate updated to {new_lr:.6f}\")\n",
    "        except Exception as e:\n",
    "            print(\"‚ö†Ô∏è Failed to update learning rate:\", e)\n",
    "        return new_lr\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        ep_end = time.time()\n",
    "        duration = ep_end - self.ep_start\n",
    "        current_lr = self.current_lr\n",
    "\n",
    "        acc = logs.get('accuracy')\n",
    "        v_acc = logs.get('val_accuracy')\n",
    "        loss = logs.get('loss')\n",
    "        v_loss = logs.get('val_loss')\n",
    "        next_lr = current_lr\n",
    "\n",
    "        if acc < self.threshold:\n",
    "            monitor = 'accuracy'\n",
    "            pimprov = 0.0 if epoch == 0 else (acc - self.highest_tracc) * 100 / self.highest_tracc\n",
    "            if acc > self.highest_tracc:\n",
    "                self.highest_tracc = acc\n",
    "                self.best_weights = self._model.get_weights()\n",
    "                self.count = 0\n",
    "                self.stop_count = 0\n",
    "                if v_loss < self.lowest_vloss:\n",
    "                    self.lowest_vloss = v_loss\n",
    "                self.best_epoch = epoch + 1\n",
    "            else:\n",
    "                if self.count >= self.patience - 1:\n",
    "                    next_lr = current_lr * self.factor\n",
    "                    self._update_lr(next_lr)\n",
    "                    self.count = 0\n",
    "                    self.stop_count += 1\n",
    "                    if v_loss < self.lowest_vloss:\n",
    "                        self.lowest_vloss = v_loss\n",
    "                else:\n",
    "                    self.count += 1\n",
    "        else:\n",
    "            monitor = 'val_loss'\n",
    "            pimprov = 0.0 if epoch == 0 else (self.lowest_vloss - v_loss) * 100 / self.lowest_vloss\n",
    "            if v_loss < self.lowest_vloss:\n",
    "                self.lowest_vloss = v_loss\n",
    "                self.best_weights = self._model.get_weights()\n",
    "                self.count = 0\n",
    "                self.stop_count = 0\n",
    "                self.best_epoch = epoch + 1\n",
    "            else:\n",
    "                if self.count >= self.patience - 1:\n",
    "                    next_lr = current_lr * self.factor\n",
    "                    self._update_lr(next_lr)\n",
    "                    self.stop_count += 1\n",
    "                    self.count = 0\n",
    "                else:\n",
    "                    self.count += 1\n",
    "                if acc > self.highest_tracc:\n",
    "                    self.highest_tracc = acc\n",
    "\n",
    "        msg = f'{epoch + 1:^8} {loss:^10.3f}{acc * 100:^9.2f}{v_loss:^9.5f}{v_acc * 100:^9.2f}{current_lr:^9.5f}{next_lr:^9.5f}{monitor:^11s}{pimprov:^10.2f}{duration:^8.2f}'\n",
    "        print(msg)\n",
    "\n",
    "        if self.stop_count > self.stop_patience - 1:\n",
    "            print(f\"\\nüõë Training halted at epoch {epoch + 1} ‚Äî no improvement after {self.stop_patience} learning rate adjustments.\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63be9ec2",
   "metadata": {},
   "source": [
    "## Code to test callback functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1b302c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Callback initialization complete.\n",
      " Epoch     Loss   Accuracy  V_loss    V_acc     LR     Next LR  Monitor  % Improv  Duration\n",
      "\n",
      "üîÅ Starting epoch 1\n",
      "Epoch 1/5\n",
      "   1       1.934     25.00   1.97165   20.00   0.00100  0.00100  accuracy     0.00     1.19   loss: 1.5473processing batch 2 of 6 - accuracy: 28.12% - loss: 1.61060 \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.2526 - loss: 1.7395 - val_accuracy: 0.2000 - val_loss: 1.9716\n",
      "\n",
      "üîÅ Starting epoch 2\n",
      "Epoch 2/5\n",
      "‚ö†Ô∏è Failed to update learning rate: 'str' object has no attribute 'name' - accuracy: 0.2044 - loss: 2.2094processing batch 2 of 6 - accuracy: 21.88% - loss: 2.19255 processing batch 5 of 6 - accuracy: 18.75% - loss: 2.03662 \n",
      "   2       2.037     18.75   1.70025   30.00   0.00100  0.00050  accuracy    -25.00    0.15  \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1988 - loss: 2.1518 - val_accuracy: 0.3000 - val_loss: 1.7002\n",
      "\n",
      "üîÅ Starting epoch 3\n",
      "Epoch 3/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2313 - loss: 1.7630processing batch 2 of 6 - accuracy: 15.62% - loss: 1.89738    3       1.616     31.25   1.45927   25.00   0.00100  0.00100  accuracy    25.00     0.12  \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2448 - loss: 1.7385 - val_accuracy: 0.2500 - val_loss: 1.4593\n",
      "\n",
      "üîÅ Starting epoch 4\n",
      "Epoch 4/5\n",
      "‚ö†Ô∏è Failed to update learning rate: 'str' object has no attribute 'name' - accuracy: 0.1875 - loss: 1.4618processing batch 2 of 6 - accuracy: 18.75% - loss: 1.46542 \n",
      "   4       1.409     25.00   1.55014   25.00   0.00100  0.00050  accuracy    -20.00    0.11  \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2161 - loss: 1.4374 - val_accuracy: 0.2500 - val_loss: 1.5501\n",
      "\n",
      "üîÅ Starting epoch 5\n",
      "Epoch 5/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3073 - loss: 1.4201processing batch 2 of 6 - accuracy: 21.88% - loss: 1.49996    5       1.369     37.50   1.52429   30.00   0.00100  0.00100  accuracy    20.00     0.12  \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3186 - loss: 1.4117 - val_accuracy: 0.3000 - val_loss: 1.5243\n",
      "\n",
      "Training time: 0h 0m 1.71s\n",
      "‚úÖ Best weights restored.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x35a058d60>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Assume your callback class is already defined above as MyCallback\n",
    "\n",
    "# 1. Create dummy image data (100 samples of 32x32 RGB images)\n",
    "X_dummy = np.random.rand(100, 32, 32, 3).astype(np.float32)\n",
    "\n",
    "# 2. Create dummy labels (4 classes)\n",
    "y_dummy = np.random.randint(0, 4, 100)\n",
    "\n",
    "# 3. Build a simple model\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(32, 32, 3)),\n",
    "    layers.Conv2D(16, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "# 4. Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 5. Create your custom callback instance\n",
    "cb = MyCallback(model=model, epochs=5, batches=X_dummy.shape[0] // 16)\n",
    "\n",
    "# 6. Train with the dummy data\n",
    "model.fit(X_dummy, y_dummy,\n",
    "          epochs=5,\n",
    "          batch_size=16,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[cb])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-metal-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
