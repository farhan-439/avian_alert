{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54cd5d59",
   "metadata": {},
   "source": [
    "\t\n",
    "## Poultry Audio Classification with Deep Learning and Burn Layer Fusion\n",
    "\n",
    "This notebook implements a deep learning-based approach for classifying poultry audio signals, inspired by the paper \"Optimizing poultry audio signal classification with deep learning and burn layer fusion\".\n",
    "\n",
    "The model uses a custom Burn Layer to enhance robustness by injecting controlled random noise during training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea883d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import random\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Check if GPU is available\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dc3a8c",
   "metadata": {},
   "source": [
    "## Custom Burn Layer Implementation\n",
    "\n",
    "The Burn Layer is a key innovation from the paper that adds controlled random noise during training to improve model robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e889cc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BurnLayer(layers.Layer):\n",
    "    def __init__(self, burn_intensity=0.2, **kwargs):\n",
    "        super(BurnLayer, self).__init__(**kwargs)\n",
    "        self.burn_intensity = burn_intensity\n",
    "    \n",
    "    def call(self, inputs, training=None):\n",
    "\n",
    "        if training:\n",
    "\n",
    "            return inputs + self.burn_intensity * tf.random.normal(shape=tf.shape(inputs))\n",
    "        else:\n",
    "\n",
    "            return inputs\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(BurnLayer, self).get_config()\n",
    "        config.update({\"burn_intensity\": self.burn_intensity})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278fefef",
   "metadata": {},
   "source": [
    "## Audio Feature Extraction and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ee55f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(audio_path, sr=44100, duration=2.0, n_mfcc=20):\n",
    "    \"\"\"\n",
    "    Extract audio features from a file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load audio file with specified sample rate and duration\n",
    "        y, sr = librosa.load(audio_path, sr=sr, duration=duration)\n",
    "        \n",
    "        # If audio is shorter than duration, pad it\n",
    "        if len(y) < int(duration * sr):\n",
    "            y = np.pad(y, (0, int(duration * sr) - len(y)))\n",
    "        \n",
    "        # Extract MFCC features\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "        \n",
    "        # Extract chromagram\n",
    "        chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        \n",
    "        # Extract spectral contrast\n",
    "        contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "        \n",
    "        # Calculate Melspectrogram\n",
    "        mel_spec = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "        \n",
    "        return y, sr, mfccs, mel_spec_db, chroma, contrast\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting features from {audio_path}: {e}\")\n",
    "        return None, None, None, None, None, None\n",
    "\n",
    "def load_and_preprocess_data(data_path, sr=44100, duration=2.0, n_mfcc=20):\n",
    "    \"\"\"\n",
    "    Load and preprocess all audio files in the dataset\n",
    "    \"\"\"\n",
    "    X_mel = []\n",
    "    y = []\n",
    "    file_paths = []\n",
    "    classes = ['Healthy', 'Noise', 'Unhealthy']\n",
    "    class_counts = {}\n",
    "    \n",
    "    for i, category in enumerate(classes):\n",
    "        path = os.path.join(data_path, category)\n",
    "        print(f\"Loading {category} samples...\")\n",
    "        count = 0\n",
    "        \n",
    "        for filename in os.listdir(path):\n",
    "            if not filename.lower().endswith('.wav'):\n",
    "                continue\n",
    "                \n",
    "            file_path = os.path.join(path, filename)\n",
    "            _, _, _, mel_spec_db, _, _ = extract_features(file_path, sr=sr, duration=duration, n_mfcc=n_mfcc)\n",
    "            \n",
    "            if mel_spec_db is not None:\n",
    "                X_mel.append(mel_spec_db)\n",
    "                y.append(i)\n",
    "                file_paths.append(file_path)\n",
    "                count += 1\n",
    "        \n",
    "        class_counts[category] = count\n",
    "        print(f\"  Loaded {count} samples for {category}\")\n",
    "    \n",
    "    X_mel = np.array(X_mel)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # Reshape mel spectrograms for CNN input\n",
    "    X_mel = X_mel.reshape(X_mel.shape[0], X_mel.shape[1], X_mel.shape[2], 1)\n",
    "    \n",
    "    return X_mel, y, file_paths, class_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2b684f",
   "metadata": {},
   "source": [
    "## Data Augmentation Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8230da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(X_mel, y, augmentation_factor=2):\n",
    "    \"\"\"\n",
    "    Perform data augmentation on mel spectrograms\n",
    "    \"\"\"\n",
    "    X_aug = []\n",
    "    y_aug = []\n",
    "    \n",
    "    # First include all original samples\n",
    "    for i in range(len(X_mel)):\n",
    "        X_aug.append(X_mel[i])\n",
    "        y_aug.append(y[i])\n",
    "    \n",
    "    # Then create augmented versions\n",
    "    for i in range(len(X_mel)):\n",
    "        mel_spec = X_mel[i].squeeze()\n",
    "        \n",
    "        # Create augmentation_factor-1 augmented versions\n",
    "        for _ in range(augmentation_factor - 1):\n",
    "            aug_mel_spec = mel_spec.copy()\n",
    "            \n",
    "            # Add random noise\n",
    "            noise_factor = np.random.uniform(0.005, 0.02)\n",
    "            noise = np.random.normal(0, noise_factor, aug_mel_spec.shape)\n",
    "            aug_mel_spec = aug_mel_spec + noise\n",
    "            \n",
    "            # Shift in time (roll)\n",
    "            shift_amount = np.random.randint(-10, 10)\n",
    "            aug_mel_spec = np.roll(aug_mel_spec, shift_amount, axis=1)\n",
    "            \n",
    "            # Frequency masking (mask random frequency bands)\n",
    "            if np.random.random() > 0.5:\n",
    "                num_masks = np.random.randint(1, 3)\n",
    "                for _ in range(num_masks):\n",
    "                    f0 = np.random.randint(0, aug_mel_spec.shape[0] - 5)\n",
    "                    f_width = np.random.randint(1, 5)\n",
    "                    aug_mel_spec[f0:f0+f_width, :] = aug_mel_spec.min()\n",
    "            \n",
    "            # Time masking (mask random time segments)\n",
    "            if np.random.random() > 0.5:\n",
    "                num_masks = np.random.randint(1, 3)\n",
    "                for _ in range(num_masks):\n",
    "                    t0 = np.random.randint(0, aug_mel_spec.shape[1] - 5)\n",
    "                    t_width = np.random.randint(1, 5)\n",
    "                    aug_mel_spec[:, t0:t0+t_width] = aug_mel_spec.min()\n",
    "            \n",
    "            # Ensure values are valid\n",
    "            aug_mel_spec = np.clip(aug_mel_spec, -80, 0)\n",
    "            \n",
    "            # Add to augmented data\n",
    "            X_aug.append(aug_mel_spec.reshape(X_mel[i].shape))\n",
    "            y_aug.append(y[i])\n",
    "    \n",
    "    return np.array(X_aug), np.array(y_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2db6941",
   "metadata": {},
   "source": [
    "## Visualization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be1666e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_audio(file_path, sr=44100, duration=2.0):\n",
    "    \"\"\"\n",
    "    Visualize audio file with waveform, MFCC, and Mel Spectrogram\n",
    "    \"\"\"\n",
    "    # Extract features\n",
    "    y, sr, mfccs, mel_spec_db, chroma, contrast = extract_features(file_path, sr=sr, duration=duration)\n",
    "    \n",
    "    if y is None:\n",
    "        print(f\"Could not load audio file: {file_path}\")\n",
    "        return\n",
    "    \n",
    "    # Create figure with 4 subplots\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    \n",
    "    # Plot waveform\n",
    "    plt.subplot(4, 1, 1)\n",
    "    librosa.display.waveshow(y, sr=sr)\n",
    "    plt.title('Waveform')\n",
    "    \n",
    "    # Plot MFCC\n",
    "    plt.subplot(4, 1, 2)\n",
    "    librosa.display.specshow(mfccs, sr=sr, x_axis='time')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('MFCCs')\n",
    "    \n",
    "    # Plot Mel Spectrogram\n",
    "    plt.subplot(4, 1, 3)\n",
    "    librosa.display.specshow(mel_spec_db, sr=sr, x_axis='time', y_axis='mel')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Mel Spectrogram')\n",
    "    \n",
    "    # Plot Chromagram\n",
    "    plt.subplot(4, 1, 4)\n",
    "    librosa.display.specshow(chroma, sr=sr, x_axis='time', y_axis='chroma')\n",
    "    plt.colorbar()\n",
    "    plt.title('Chromagram')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_augmentation(X_mel, index, augmentation_factor=3):\n",
    "    \"\"\"\n",
    "    Visualize original and augmented mel spectrograms\n",
    "    \"\"\"\n",
    "    # Get original mel spectrogram\n",
    "    original_mel = X_mel[index].squeeze()\n",
    "    \n",
    "    # Create augmented versions\n",
    "    augmented_mels = []\n",
    "    for _ in range(augmentation_factor):\n",
    "        aug_mel = original_mel.copy()\n",
    "        \n",
    "        # Add random noise\n",
    "        noise_factor = np.random.uniform(0.005, 0.02)\n",
    "        noise = np.random.normal(0, noise_factor, aug_mel.shape)\n",
    "        aug_mel = aug_mel + noise\n",
    "        \n",
    "        # Shift in time (roll)\n",
    "        shift_amount = np.random.randint(-10, 10)\n",
    "        aug_mel = np.roll(aug_mel, shift_amount, axis=1)\n",
    "        \n",
    "        # Frequency masking\n",
    "        if np.random.random() > 0.5:\n",
    "            f0 = np.random.randint(0, aug_mel.shape[0] - 5)\n",
    "            f_width = np.random.randint(1, 5)\n",
    "            aug_mel[f0:f0+f_width, :] = aug_mel.min()\n",
    "        \n",
    "        # Time masking\n",
    "        if np.random.random() > 0.5:\n",
    "            t0 = np.random.randint(0, aug_mel.shape[1] - 5)\n",
    "            t_width = np.random.randint(1, 5)\n",
    "            aug_mel[:, t0:t0+t_width] = aug_mel.min()\n",
    "        \n",
    "        augmented_mels.append(aug_mel)\n",
    "    \n",
    "    # Visualize original and augmented spectrograms\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Original\n",
    "    plt.subplot(2, 2, 1)\n",
    "    librosa.display.specshow(original_mel, x_axis='time', y_axis='mel')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Original Mel Spectrogram')\n",
    "    \n",
    "    # Augmented versions\n",
    "    for i, aug_mel in enumerate(augmented_mels):\n",
    "        plt.subplot(2, 2, i+2)\n",
    "        librosa.display.specshow(aug_mel, x_axis='time', y_axis='mel')\n",
    "        plt.colorbar(format='%+2.0f dB')\n",
    "        plt.title(f'Augmented Version {i+1}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0deb4d7",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "This model implements the architecture described in the paper, with convolutional blocks, Burn Layer and global average pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61283035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_burn_model(input_shape, num_classes=3):\n",
    "    \"\"\"\n",
    "    Build the model with Burn Layer as described in the paper\n",
    "    \"\"\"\n",
    "    # Input tensor\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Apply initial Burn Layer to input\n",
    "    x = BurnLayer(burn_intensity=0.2)(inputs)\n",
    "    \n",
    "    # First convolutional block\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    # Second convolutional block\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    # Third convolutional block\n",
    "    x = layers.Conv2D(256, (3, 3), padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    # Global average pooling to create a fusion layer\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # Dense layer\n",
    "    x = layers.Dense(256)(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Dropout(0.6)(x)\n",
    "    \n",
    "    # Second Burn Layer with reduced intensity\n",
    "    x = BurnLayer(burn_intensity=0.1)(x)\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # Compile with Adamax optimizer as used in the paper\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adamax(learning_rate=0.001),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-metal-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
