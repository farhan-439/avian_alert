{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54cd5d59",
   "metadata": {},
   "source": [
    "\t\n",
    "## Poultry Audio Classification with Deep Learning and Burn Layer Fusion\n",
    "\n",
    "This notebook implements a deep learning-based approach for classifying poultry audio signals, inspired by the paper \"Optimizing poultry audio signal classification with deep learning and burn layer fusion\".\n",
    "\n",
    "The model uses a custom Burn Layer to enhance robustness by injecting controlled random noise during training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea883d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/farhanmashrur/Desktop/cds/avian_alert/tf-metal-env/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import random\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Check if GPU is available\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dc3a8c",
   "metadata": {},
   "source": [
    "## Custom Burn Layer Implementation\n",
    "\n",
    "The Burn Layer is a key innovation from the paper that adds controlled random noise during training to improve model robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e889cc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BurnLayer(layers.Layer):\n",
    "    def __init__(self, burn_intensity=0.2, **kwargs):\n",
    "        super(BurnLayer, self).__init__(**kwargs)\n",
    "        self.burn_intensity = burn_intensity\n",
    "    \n",
    "    def call(self, inputs, training=None):\n",
    "\n",
    "        if training:\n",
    "\n",
    "            return inputs + self.burn_intensity * tf.random.normal(shape=tf.shape(inputs))\n",
    "        else:\n",
    "\n",
    "            return inputs\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(BurnLayer, self).get_config()\n",
    "        config.update({\"burn_intensity\": self.burn_intensity})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278fefef",
   "metadata": {},
   "source": [
    "## Audio Feature Extraction and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ee55f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(audio_path, sr=44100, duration=2.0, n_mfcc=20):\n",
    "    \"\"\"\n",
    "    Extract audio features from a file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load audio file with specified sample rate and duration\n",
    "        y, sr = librosa.load(audio_path, sr=sr, duration=duration)\n",
    "        \n",
    "        # If audio is shorter than duration, pad it\n",
    "        if len(y) < int(duration * sr):\n",
    "            y = np.pad(y, (0, int(duration * sr) - len(y)))\n",
    "        \n",
    "        # Extract MFCC features\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "        \n",
    "        # Extract chromagram\n",
    "        chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        \n",
    "        # Extract spectral contrast\n",
    "        contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "        \n",
    "        # Calculate Melspectrogram\n",
    "        mel_spec = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "        \n",
    "        return y, sr, mfccs, mel_spec_db, chroma, contrast\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting features from {audio_path}: {e}\")\n",
    "        return None, None, None, None, None, None\n",
    "\n",
    "def load_and_preprocess_data(data_path, sr=44100, duration=2.0, n_mfcc=20):\n",
    "    \"\"\"\n",
    "    Load and preprocess all audio files in the dataset\n",
    "    \"\"\"\n",
    "    X_mel = []\n",
    "    y = []\n",
    "    file_paths = []\n",
    "    classes = ['Healthy', 'Noise', 'Unhealthy']\n",
    "    class_counts = {}\n",
    "    \n",
    "    for i, category in enumerate(classes):\n",
    "        path = os.path.join(data_path, category)\n",
    "        print(f\"Loading {category} samples...\")\n",
    "        count = 0\n",
    "        \n",
    "        for filename in os.listdir(path):\n",
    "            if not filename.lower().endswith('.wav'):\n",
    "                continue\n",
    "                \n",
    "            file_path = os.path.join(path, filename)\n",
    "            _, _, _, mel_spec_db, _, _ = extract_features(file_path, sr=sr, duration=duration, n_mfcc=n_mfcc)\n",
    "            \n",
    "            if mel_spec_db is not None:\n",
    "                X_mel.append(mel_spec_db)\n",
    "                y.append(i)\n",
    "                file_paths.append(file_path)\n",
    "                count += 1\n",
    "        \n",
    "        class_counts[category] = count\n",
    "        print(f\"  Loaded {count} samples for {category}\")\n",
    "    \n",
    "    X_mel = np.array(X_mel)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # Reshape mel spectrograms for CNN input\n",
    "    X_mel = X_mel.reshape(X_mel.shape[0], X_mel.shape[1], X_mel.shape[2], 1)\n",
    "    \n",
    "    return X_mel, y, file_paths, class_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-metal-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
